{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"EoRP98MpR-qj"},"source":["# 🛠️ Data Preprocessing Template 🛠️"]},{"cell_type":"code","source":["# 🛠️ Data Preprocessing Template (Python Version) 🛠️\n","# This script includes essential steps for preparing data in Python before applying machine learning models."],"metadata":{"id":"SVuulz4uUUeU","executionInfo":{"status":"ok","timestamp":1739854364017,"user_tz":480,"elapsed":299,"user":{"displayName":"Evgenii Matveev","userId":"17368348035028880030"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["## Importing the libraries"],"metadata":{"id":"gUeE_klJsG62"}},{"cell_type":"code","metadata":{"id":"N-qiINBQSK2g","executionInfo":{"status":"ok","timestamp":1739854367497,"user_tz":480,"elapsed":2059,"user":{"displayName":"Evgenii Matveev","userId":"17368348035028880030"}}},"source":["# ------------------------------------------\n","# 📌 1. Importing the necessary libraries\n","# ------------------------------------------\n","import numpy as np  # 🔢 NumPy: Used for numerical operations and handling arrays\n","import pandas as pd  # 📑 Pandas: Used for data manipulation and analysis\n","from sklearn.model_selection import train_test_split  # 🔀 For splitting dataset into training and test sets\n","from sklearn.preprocessing import LabelEncoder, StandardScaler  # 🔄 For encoding categorical variables and feature scaling"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RopL7tUZSQkT"},"source":["## Importing the dataset"]},{"cell_type":"code","metadata":{"id":"WwEPNDWySTKm","executionInfo":{"status":"ok","timestamp":1739854395600,"user_tz":480,"elapsed":308,"user":{"displayName":"Evgenii Matveev","userId":"17368348035028880030"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"eefa3304-74a0-4e84-fd40-7f7afd548f12"},"source":["# ------------------------------------------\n","# 📌 2. Loading the dataset\n","# ------------------------------------------\n","# Read the dataset from a CSV file\n","# `pd.read_csv(\"filename.csv\")` loads tabular data from a CSV file into a DataFrame\n","dataset = pd.read_csv(\"Data.csv\")\n","\n","# Display basic information about the dataset\n","dataset.info()  # 📊 Shows dataset structure, column types, and missing values\n","print(dataset.head())  # 🔍 Displays the first few rows of the dataset\n","\n","# 🔹 X (features) - All columns except the last one (independent variables)\n","X = dataset.iloc[:, :-1].values\n","\n","# 🔹 y (target) - Only the last column (dependent variable)\n","y = dataset.iloc[:, -1].values"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 10 entries, 0 to 9\n","Data columns (total 4 columns):\n"," #   Column     Non-Null Count  Dtype  \n","---  ------     --------------  -----  \n"," 0   Country    10 non-null     object \n"," 1   Age        9 non-null      float64\n"," 2   Salary     9 non-null      float64\n"," 3   Purchased  10 non-null     object \n","dtypes: float64(2), object(2)\n","memory usage: 452.0+ bytes\n","   Country   Age   Salary Purchased\n","0   France  44.0  72000.0        No\n","1    Spain  27.0  48000.0       Yes\n","2  Germany  30.0  54000.0        No\n","3    Spain  38.0  61000.0        No\n","4  Germany  40.0      NaN       Yes\n"]}]},{"cell_type":"code","metadata":{"id":"hCsz2yCebe1R","outputId":"9b67766f-b3cb-4723-e91f-7c71b20eeef7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739854430878,"user_tz":480,"elapsed":299,"user":{"displayName":"Evgenii Matveev","userId":"17368348035028880030"}}},"source":["print(X)  # 📃 Print feature matrix"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["[['France' 44.0 72000.0]\n"," ['Spain' 27.0 48000.0]\n"," ['Germany' 30.0 54000.0]\n"," ['Spain' 38.0 61000.0]\n"," ['Germany' 40.0 nan]\n"," ['France' 35.0 58000.0]\n"," ['Spain' nan 52000.0]\n"," ['France' 48.0 79000.0]\n"," ['Germany' 50.0 83000.0]\n"," ['France' 37.0 67000.0]]\n"]}]},{"cell_type":"code","metadata":{"id":"eYrOQ43XcJR3","outputId":"da3a9eeb-6678-4f7e-ab63-7a5d6d5fd2e6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739854427281,"user_tz":480,"elapsed":288,"user":{"displayName":"Evgenii Matveev","userId":"17368348035028880030"}}},"source":["print(y)  # 🎯 Print target variable"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"]}]},{"cell_type":"markdown","metadata":{"id":"nhfKXNxlSabC"},"source":["## Taking care of missing data"]},{"cell_type":"code","metadata":{"id":"c93k7ipkSexq"},"source":["# ------------------------------------------\n","# 📌 Handling Missing Data\n","# ------------------------------------------\n","# In real-world datasets, missing values (NaN) are common and can negatively impact model performance.\n","# Instead of removing entire rows or columns with missing values (which can lead to data loss),\n","# we replace them with an appropriate statistic such as the mean.\n","\n","# ------------------------------------------\n","# 📌 1. Importing the required library\n","# ------------------------------------------\n","from sklearn.impute import SimpleImputer  # 🛠 Import SimpleImputer to handle missing values\n","\n","# ------------------------------------------\n","# 📌 2. Creating an Imputer instance\n","# ------------------------------------------\n","# The imputer is responsible for filling missing values in numerical columns.\n","# - `missing_values=np.nan` → Specifies that we are handling NaN (Not a Number) values.\n","# - `strategy='mean'` → Fills NaN values with the **mean** of the respective column.\n","#\n","# 🔹 Other strategies available:\n","#   - `median` → Fills NaN values with the **median** of the column.\n","#   - `most_frequent` → Replaces NaN with the most frequently occurring value in the column (useful for categorical data).\n","#   - `constant` → Replaces NaN with a specified constant value (e.g., 0).\n","imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n","\n","# ------------------------------------------\n","# 📌 3. Applying the imputer to numerical features\n","# ------------------------------------------\n","# We assume that missing values exist only in numerical columns (e.g., Age, Salary).\n","# - `fit_transform()` first calculates the mean for each column and replaces NaN values.\n","# - `X[:, 1:3]` selects the **second and third columns** (indexing starts from 0).\n","#\n","# 🚨 Important:\n","#   - Ensure these columns contain only numerical values before applying the imputer.\n","#   - If categorical variables exist in this range, encoding should be done first.\n","X[:, 1:3] = imputer.fit_transform(X[:, 1:3])\n","\n","# ------------------------------------------\n","# 📌 4. Checking the results\n","# ------------------------------------------\n","# Let's print `X` to verify that missing values have been successfully replaced.\n","print(X)  # 🖨 Displays the feature matrix after imputation"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3UgLdMS_bjq_","outputId":"4943a29b-0633-48de-f937-ed2eb720b6ce","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739854821451,"user_tz":480,"elapsed":305,"user":{"displayName":"Evgenii Matveev","userId":"17368348035028880030"}}},"source":["# Let's print `X` to verify that missing values have been successfully replaced.\n","print(X)  # 🖨 Displays the feature matrix after imputation"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1.0 0.0 0.0 44.0 72000.0]\n"," [0.0 0.0 1.0 27.0 48000.0]\n"," [0.0 1.0 0.0 30.0 54000.0]\n"," [0.0 0.0 1.0 38.0 61000.0]\n"," [0.0 1.0 0.0 40.0 nan]\n"," [1.0 0.0 0.0 35.0 58000.0]\n"," [0.0 0.0 1.0 nan 52000.0]\n"," [1.0 0.0 0.0 48.0 79000.0]\n"," [0.0 1.0 0.0 50.0 83000.0]\n"," [1.0 0.0 0.0 37.0 67000.0]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"CriG6VzVSjcK"},"source":["## Encoding categorical data"]},{"cell_type":"markdown","metadata":{"id":"AhSpdQWeSsFh"},"source":["### Encoding the Independent Variable"]},{"cell_type":"code","metadata":{"id":"5hwuVddlSwVi","executionInfo":{"status":"ok","timestamp":1739855174343,"user_tz":480,"elapsed":301,"user":{"displayName":"Evgenii Matveev","userId":"17368348035028880030"}}},"source":["# ------------------------------------------\n","# 📌 Encoding Categorical Data (Independent Variable)\n","# ------------------------------------------\n","# Machine learning models cannot work directly with categorical (text) data.\n","# Instead, we need to transform categorical values into numerical representations.\n","#\n","# There are two common encoding techniques:\n","# 1️⃣ **Label Encoding**: Assigns a unique number to each category (e.g., France → 0, Spain → 1, Germany → 2).\n","#    - Suitable for ordinal data (where order matters).\n","# 2️⃣ **One-Hot Encoding** (used here): Converts categorical values into binary vectors.\n","#    - Each unique category gets its own column.\n","#    - Example: ['France', 'Spain', 'Germany'] → [1 0 0], [0 1 0], [0 0 1]\n","#    - Suitable for non-ordinal data (where order **does not** matter).\n","\n","# ------------------------------------------\n","# 📌 1. Importing Required Libraries\n","# ------------------------------------------\n","from sklearn.compose import ColumnTransformer  # 🛠 Helps apply transformations to specific columns\n","from sklearn.preprocessing import OneHotEncoder  # 🔄 One-Hot Encoding transformation\n","\n","# ------------------------------------------\n","# 📌 2. Applying One-Hot Encoding to the 'Country' column\n","# ------------------------------------------\n","# - `transformers=[('encoder', OneHotEncoder(), [0])]` → Applies One-Hot Encoding to the first column (Country).\n","# - `remainder='passthrough'` → Keeps the rest of the dataset unchanged.\n","# - This ensures that only the categorical feature is transformed, while numerical features remain intact.\n","\n","ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n","\n","# ------------------------------------------\n","# 📌 3. Transforming the Dataset\n","# ------------------------------------------\n","# - `fit_transform(X)` applies the transformation.\n","# - `np.array(...)` ensures that the transformed dataset is stored as a NumPy array.\n","X = np.array(ct.fit_transform(X))"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"f7QspewyeBfx","outputId":"6fc8cca8-dfc0-499a-c965-023816182a7a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739855582860,"user_tz":480,"elapsed":281,"user":{"displayName":"Evgenii Matveev","userId":"17368348035028880030"}}},"source":["#✅ Checking the Transformed Dataset\n","# ------------------------------------------\n","# Printing `X` to verify that the categorical feature is now represented as binary vectors.\n","print(X)  # 🖨 Displays the dataset after encoding"],"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 1.0 0.0 0.0 44.0 72000.0]\n"," [1.0 0.0 0.0 1.0 27.0 48000.0]\n"," [1.0 0.0 1.0 0.0 30.0 54000.0]\n"," [1.0 0.0 0.0 1.0 38.0 61000.0]\n"," [1.0 0.0 1.0 0.0 40.0 nan]\n"," [0.0 1.0 0.0 0.0 35.0 58000.0]\n"," [1.0 0.0 0.0 1.0 nan 52000.0]\n"," [0.0 1.0 0.0 0.0 48.0 79000.0]\n"," [1.0 0.0 1.0 0.0 50.0 83000.0]\n"," [0.0 1.0 0.0 0.0 37.0 67000.0]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"DXh8oVSITIc6"},"source":["### Encoding the Dependent Variable"]},{"cell_type":"code","metadata":{"id":"XgHCShVyTOYY","executionInfo":{"status":"ok","timestamp":1739855847989,"user_tz":480,"elapsed":398,"user":{"displayName":"Evgenii Matveev","userId":"17368348035028880030"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cd0f9822-00b3-4394-b9e7-77cadc6aecb2"},"source":["# ------------------------------------------\n","# 🏷️ Encoding the Dependent Variable (Target)\n","# ------------------------------------------\n","# 📌 Why do we need to encode the target variable?\n","# Machine learning models work with numerical data, but our target variable (`y`) contains categorical values.\n","# Example: \"Yes\" and \"No\" → These need to be converted into numerical labels (e.g., 1 and 0).\n","#\n","# 🔹 Solution: We use **Label Encoding**, which assigns each category a unique integer.\n","# - Example transformation:\n","#   [\"No\", \"Yes\", \"No\", \"Yes\"] → [0, 1, 0, 1]\n","# - This works well for **binary classification** problems.\n","\n","# ------------------------------------------\n","# 📌 1. Importing Required Library\n","# ------------------------------------------\n","from sklearn.preprocessing import LabelEncoder  # 🛠 Import LabelEncoder to encode categorical target variables\n","\n","# ------------------------------------------\n","# 📌 2. Creating and Applying Label Encoding\n","# ------------------------------------------\n","# 🔹 Label Encoding converts categorical labels into numeric values:\n","# Each unique category in `y` gets a distinct integer.\n","# This is useful for **binary target variables** (like Yes/No, Purchased/Not Purchased).\n","\n","le = LabelEncoder()  # 🛠 Creating an instance of LabelEncoder\n","\n","# 🚀 Applying the transformation\n","y = le.fit_transform(y)\n","# ------------------------------------------\n","# 📌 3. Checking the Encoded Target Variable\n","# ------------------------------------------\n","# 🔍 Let's print `y` to verify that categorical values have been successfully converted into numerical labels.\n","print(\"Encoded Target Variable:\")\n","print(y)  # 🖨 Displays the transformed target variable\n","\n","# ------------------------------------------\n","# 🔥 Alternative Approach: One-Hot Encoding for Multi-Class Target\n","# ------------------------------------------\n","# If the target variable had **more than two categories**, we could use One-Hot Encoding instead.\n","# Example: [\"Low\", \"Medium\", \"High\"] → [[1,0,0], [0,1,0], [0,0,1]]\n","# However, for **binary classification**, Label Encoding is the best choice.\n","\n","# ✅ Now, the target variable (`y`) is encoded and ready for machine learning models!"],"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoded Target Variable:\n","[0 1 0 0 1 1 0 1 0 1]\n"]}]},{"cell_type":"code","metadata":{"id":"FyhY8-gPpFCa","outputId":"0919302e-7be3-49c5-fba5-1377a4a55914","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739854630319,"user_tz":480,"elapsed":319,"user":{"displayName":"Evgenii Matveev","userId":"17368348035028880030"}}},"source":["# 📌  Checking the Encoded Target Variable\n","# ------------------------------------------\n","# Let's print `y` to verify that categorical values have been converted to numerical labels.\n","print(y)  # 🖨 Displays the transformed target variable\n"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 0 0 1 1 0 1 0 1]\n"]}]},{"cell_type":"markdown","metadata":{"id":"qb_vcgm3qZKW"},"source":["## Splitting the dataset into the Training set and Test set"]},{"cell_type":"code","metadata":{"id":"pXgA6CzlqbCl","executionInfo":{"status":"ok","timestamp":1739856056413,"user_tz":480,"elapsed":336,"user":{"displayName":"Evgenii Matveev","userId":"17368348035028880030"}}},"source":["# ------------------------------------------\n","# 🎯 Splitting the Dataset into Training and Test Sets\n","# ------------------------------------------\n","# 📌 Why do we split the dataset?\n","# - Machine learning models learn from **training data** (X_train, y_train).\n","# - The model's performance is **evaluated on unseen test data** (X_test, y_test).\n","# - Typically, we use **80%** of the data for training and **20%** for testing.\n","\n","# ------------------------------------------\n","# 📌 1. Importing Required Library\n","# ------------------------------------------\n","from sklearn.model_selection import train_test_split  # 🔀 Import function for splitting data\n","\n","# ------------------------------------------\n","# 📌 2. Splitting the Data\n","# ------------------------------------------\n","# - `test_size=0.2` → Allocates 20% of the dataset for testing.\n","# - `random_state=1` → Ensures **reproducibility** (so we get the same split every time).\n","# - `train_test_split` automatically shuffles and splits the dataset.\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n","\n","# ------------------------------------------\n","# 📌 3. Understanding the Split\n","# ------------------------------------------\n","# Now, we have:\n","# ✅ `X_train`, `y_train` → Training set (80% of data)\n","# ✅ `X_test`, `y_test` → Test set (20% of data)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"GuwQhFdKrYTM","outputId":"a2013819-1d80-49a0-bbec-b3a221d085a6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739856099339,"user_tz":480,"elapsed":284,"user":{"displayName":"Evgenii Matveev","userId":"17368348035028880030"}}},"source":["# 🧐 Checking the training set\n","print(\"Training Features (X_train):\")\n","print(X_train)  # 🖨 Print training features"],"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Features (X_train):\n","[[1.0 0.0 0.0 1.0 nan 52000.0]\n"," [1.0 0.0 1.0 0.0 40.0 nan]\n"," [0.0 1.0 0.0 0.0 44.0 72000.0]\n"," [1.0 0.0 0.0 1.0 38.0 61000.0]\n"," [1.0 0.0 0.0 1.0 27.0 48000.0]\n"," [0.0 1.0 0.0 0.0 48.0 79000.0]\n"," [1.0 0.0 1.0 0.0 50.0 83000.0]\n"," [0.0 1.0 0.0 0.0 35.0 58000.0]]\n"]}]},{"cell_type":"code","metadata":{"id":"TUrX_Tvcrbi4","outputId":"c9c1a76f-5515-4199-f66f-7e026bd92407","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739856151700,"user_tz":480,"elapsed":848,"user":{"displayName":"Evgenii Matveev","userId":"17368348035028880030"}}},"source":["# 🧐 Checking the test set\n","print(\"\\nTest Features (X_test):\")\n","print(X_test)  # 🖨 Print test features"],"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Test Features (X_test):\n","[[1.0 0.0 1.0 0.0 30.0 54000.0]\n"," [0.0 1.0 0.0 0.0 37.0 67000.0]]\n"]}]},{"cell_type":"code","metadata":{"id":"pSMHiIsWreQY","outputId":"cc1419dd-bac4-403c-a548-20f24c2ec5a9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739856184909,"user_tz":480,"elapsed":304,"user":{"displayName":"Evgenii Matveev","userId":"17368348035028880030"}}},"source":["print(\"\\nTraining Target Labels (y_train):\")\n","print(y_train)  # 🖨 Print training target labels"],"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training Target Labels (y_train):\n","[0 1 0 0 1 1 0 1]\n"]}]},{"cell_type":"code","metadata":{"id":"I_tW7H56rgtW","outputId":"c6f425e8-623f-4a28-f2d5-133feaaa52d4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739856367084,"user_tz":480,"elapsed":277,"user":{"displayName":"Evgenii Matveev","userId":"17368348035028880030"}}},"source":["print(\"\\nTest Target Labels (y_test):\")\n","print(y_test)  # 🖨 Print test target labels"],"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Test Target Labels (y_test):\n","[0 1]\n"]}]},{"cell_type":"markdown","metadata":{"id":"TpGqbS4TqkIR"},"source":["## Feature Scaling"]},{"cell_type":"code","metadata":{"id":"AxjSUXFQqo-3","executionInfo":{"status":"ok","timestamp":1739856303305,"user_tz":480,"elapsed":309,"user":{"displayName":"Evgenii Matveev","userId":"17368348035028880030"}}},"source":["# ------------------------------------------\n","# ⚙️ Feature Scaling - Normalizing numerical data to improve performance\n","# ------------------------------------------\n","# 📌 Why apply feature scaling?\n","# - Some ML models (e.g., SVM, KNN, Logistic Regression) perform **better with scaled data**.\n","# - Prevents **features with large values** (like Salary) from dominating smaller ones (like Age).\n","# - Improves **convergence speed** for gradient-based models (e.g., Neural Networks).\n","\n","# ------------------------------------------\n","# 📌 1. Importing Required Library\n","# ------------------------------------------\n","from sklearn.preprocessing import StandardScaler  # 📏 Import StandardScaler\n","\n","# ------------------------------------------\n","# 📌 2. Creating an Instance of StandardScaler\n","# ------------------------------------------\n","# Standardization formula:\n","#   X_scaled = (X - mean) / standard deviation\n","# This ensures that each feature has:\n","# - Mean = 0\n","# - Standard Deviation = 1\n","sc = StandardScaler()  # 🛠 Create an instance of the scaler\n","\n","# ------------------------------------------\n","# 📌 3. Applying Scaling to the Numerical Features\n","# ------------------------------------------\n","# 🚨 Note:\n","# - We **do NOT** scale categorical variables (already encoded).\n","# - We apply scaling **only to numerical columns**.\n","\n","# Apply scaling to numerical features in the training set\n","X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\n","\n","# Apply the same transformation to the test set\n","X_test[:, 3:] = sc.transform(X_test[:, 3:])  # 🚨 Use `transform()` (not `fit_transform()`)"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"DWPET8ZdlMnu","outputId":"7e2497b7-ef1d-4f43-bf38-bc39c28e6256","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739856345162,"user_tz":480,"elapsed":285,"user":{"displayName":"Evgenii Matveev","userId":"17368348035028880030"}}},"source":["# 🔍 Print Scaled Training Set\n","print(\"📊 Scaled Training Features (X_train):\")\n","print(X_train)  # 🖨 Display transformed training data"],"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["📊 Scaled Training Features (X_train):\n","[[1.0 0.0 0.0 1.2909944487358056 nan -1.0182239953527132]\n"," [1.0 0.0 1.0 -0.7745966692414834 -0.038910211282047996 nan]\n"," [0.0 1.0 0.0 -0.7745966692414834 0.5058327466666259 0.583476671494251]\n"," [1.0 0.0 0.0 1.2909944487358056 -0.3112816902563849 -0.2974586952715793]\n"," [1.0 0.0 0.0 1.2909944487358056 -1.809324824615238 -1.3385641287221062]\n"," [0.0 1.0 0.0 -0.7745966692414834 1.0505757046152997 1.1440719048906884]\n"," [1.0 0.0 1.0 -0.7745966692414834 1.3229471835896367 1.4644120382600814]\n"," [0.0 1.0 0.0 -0.7745966692414834 -0.7198389087178904 -0.537713795298624]]\n"]}]},{"cell_type":"code","metadata":{"id":"sTXykB_QlRjE","outputId":"c32a13f1-9af0-47e8-85f2-6c563acd5c2a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739856349705,"user_tz":480,"elapsed":304,"user":{"displayName":"Evgenii Matveev","userId":"17368348035028880030"}}},"source":["# 🔍 Print Scaled Test Set\n","print(\"\\n📊 Scaled Test Features (X_test):\")\n","print(X_test)  # 🖨 Display transformed test data"],"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","📊 Scaled Test Features (X_test):\n","[[1.0 0.0 1.0 -0.7745966692414834 -1.4007676061537326 -0.8580539286680168]\n"," [0.0 1.0 0.0 -0.7745966692414834 -0.4474674297435534 0.18305150478250995]]\n"]}]}]}